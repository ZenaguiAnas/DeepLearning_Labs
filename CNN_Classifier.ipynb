{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r-MpIT3KhxwM",
        "outputId": "80171356-7d86-418b-8fb0-a96638543153"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1,   100] loss: 0.711\n",
            "[1,   200] loss: 0.168\n",
            "[1,   300] loss: 0.120\n",
            "[1,   400] loss: 0.096\n",
            "[1,   500] loss: 0.085\n",
            "[1,   600] loss: 0.068\n",
            "[1,   700] loss: 0.075\n",
            "[1,   800] loss: 0.066\n",
            "[1,   900] loss: 0.064\n",
            "[2,   100] loss: 0.046\n",
            "[2,   200] loss: 0.044\n",
            "[2,   300] loss: 0.053\n",
            "[2,   400] loss: 0.039\n",
            "[2,   500] loss: 0.051\n",
            "[2,   600] loss: 0.046\n",
            "[2,   700] loss: 0.046\n",
            "[2,   800] loss: 0.039\n",
            "[2,   900] loss: 0.042\n",
            "Finished Training\n",
            "Accuracy of the network on the 10000 test images: 98 %\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),  # Convert images to tensors\n",
        "    transforms.Normalize((0.5,), (0.5,))  # Normalize the pixel values\n",
        "])\n",
        "\n",
        "trainset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "testset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False)\n",
        "\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
        "        self.fc1 = nn.Linear(64 * 7 * 7, 128) \n",
        "        self.fc2 = nn.Linear(128, 10)  \n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(torch.relu(self.conv1(x)))\n",
        "        x = self.pool(torch.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 64 * 7 * 7) \n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "model = CNN().to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "for epoch in range(2):  \n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        inputs, labels = data[0].to(device), data[1].to(device)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        if i % 100 == 99:  \n",
        "            print('[%d, %5d] loss: %.3f' % (epoch + 1, i + 1, running_loss / 100))\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('Finished Training')\n",
        "\n",
        "# Evaluate the model\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data[0].to(device), data[1].to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % (100 * correct / total))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "pggeP_TTrnwT"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torchvision.models.detection import FasterRCNN\n",
        "from torchvision.models.detection.rpn import AnchorGenerator\n",
        "from torchvision.transforms import ToTensor\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.datasets import MNIST\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "\n",
        "class MNISTObjectDetectionDataset(Dataset):\n",
        "    def __init__(self, mnist_dataset):\n",
        "        self.mnist_dataset = mnist_dataset\n",
        "        self.transform = transforms.Compose([\n",
        "            transforms.ToPILImage(),\n",
        "            transforms.Resize((64, 64)),  # Resize images to fit the expected input size of Faster R-CNN\n",
        "            transforms.ToTensor(),\n",
        "        ])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.mnist_dataset)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image, label = self.mnist_dataset[idx]\n",
        "        image = self.transform(image)\n",
        "        target = {\n",
        "            \"boxes\": torch.tensor([[0, 0, 64, 64]], dtype=torch.float32),  # Assuming single bounding box for entire image\n",
        "            \"labels\": torch.tensor([label], dtype=torch.int64),\n",
        "        }\n",
        "        return image, target\n",
        "\n",
        "# Load MNIST dataset\n",
        "mnist_train = MNIST(root='./data', train=True, download=True, transform=ToTensor())\n",
        "mnist_test = MNIST(root='./data', train=False, download=True, transform=ToTensor())\n",
        "\n",
        "# Create Faster R-CNN model\n",
        "backbone = torchvision.models.mobilenet_v2(pretrained=True).features\n",
        "backbone.out_channels = 1280  # Adjusting backbone output channels\n",
        "anchor_generator = AnchorGenerator(sizes=((32, 64, 128, 256, 512),),\n",
        "                                   aspect_ratios=((0.5, 1.0, 2.0),))\n",
        "roi_pooler = torchvision.ops.MultiScaleRoIAlign(featmap_names=['0'],\n",
        "                                                 output_size=7,\n",
        "                                                 sampling_ratio=2)\n",
        "model = FasterRCNN(backbone,\n",
        "                   num_classes=10,  # 10 classes for digits 0-9\n",
        "                   rpn_anchor_generator=anchor_generator,\n",
        "                   box_roi_pool=roi_pooler)\n",
        "\n",
        "# Convert MNIST dataset to object detection dataset\n",
        "train_dataset = MNISTObjectDetectionDataset(mnist_train)\n",
        "test_dataset = MNISTObjectDetectionDataset(mnist_test)\n",
        "\n",
        "# DataLoader\n",
        "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True, num_workers=4)\n",
        "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False, num_workers=4)\n",
        "\n",
        "# Define device\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "\n",
        "# Move model to device\n",
        "model.to(device)\n",
        "\n",
        "# Define optimizer and loss function\n",
        "params = [p for p in model.parameters() if p.requires_grad]\n",
        "optimizer = torch.optim.SGD(params, lr=0.005, momentum=0.9, weight_decay=0.0005)\n",
        "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 456
        },
        "id": "k-2ZhF6psyLR",
        "outputId": "1306829f-071e-462e-d796-a769a02d28bb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1, Loss: 0.16699306400212796\n",
            "Epoch 2, Loss: 0.046605426322808785\n",
            "Training time: 30.359601497650146 seconds\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "ename": "AttributeError",
          "evalue": "'dict' object has no attribute 'to'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-017b5b2a51b7>\u001b[0m in \u001b[0;36m<cell line: 56>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0mfaster_rcnn_criterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m \u001b[0mfaster_rcnn_accuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfaster_rcnn_f1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_and_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfaster_rcnn_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfaster_rcnn_criterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfaster_rcnn_optimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;31m# Print results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-11-017b5b2a51b7>\u001b[0m in \u001b[0;36mtrain_and_evaluate\u001b[0;34m(model, train_loader, test_loader, criterion, optimizer, num_epochs)\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mrunning_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m             \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'to'"
          ]
        }
      ],
      "source": [
        "import time\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "import numpy as np\n",
        "\n",
        "# Define function to train and evaluate a model\n",
        "def train_and_evaluate(model, train_loader, test_loader, criterion, optimizer, num_epochs=2):\n",
        "    start_time = time.time()\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        for images, labels in train_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        # Print average loss after each epoch\n",
        "        print(f\"Epoch {epoch+1}, Loss: {running_loss/len(train_loader)}\")\n",
        "\n",
        "    end_time = time.time()\n",
        "    print(f\"Training time: {end_time - start_time} seconds\")\n",
        "\n",
        "    # Evaluate model on test set\n",
        "    model.eval()\n",
        "    test_predictions = []\n",
        "    true_labels = []\n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            test_predictions.extend(predicted.cpu().numpy())\n",
        "            true_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    # Calculate accuracy and F1 score\n",
        "    accuracy = accuracy_score(true_labels, test_predictions)\n",
        "    f1 = f1_score(true_labels, test_predictions, average='weighted')\n",
        "\n",
        "    return accuracy, f1\n",
        "\n",
        "# Train and evaluate CNN model\n",
        "cnn_model = CNN().to(device)\n",
        "cnn_optimizer = optim.Adam(cnn_model.parameters(), lr=0.001)\n",
        "cnn_criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "cnn_accuracy, cnn_f1 = train_and_evaluate(cnn_model, trainloader, testloader, cnn_criterion, cnn_optimizer)\n",
        "\n",
        "# Train and evaluate Faster R-CNN model (For illustration purposes)\n",
        "faster_rcnn_model = model\n",
        "faster_rcnn_optimizer = optimizer\n",
        "faster_rcnn_criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "faster_rcnn_accuracy, faster_rcnn_f1 = train_and_evaluate(faster_rcnn_model, train_loader, test_loader, faster_rcnn_criterion, faster_rcnn_optimizer)\n",
        "\n",
        "# Print results\n",
        "print(\"CNN Model:\")\n",
        "print(\"Accuracy:\", cnn_accuracy)\n",
        "print(\"F1 Score:\", cnn_f1)\n",
        "\n",
        "print(\"Faster R-CNN Model:\")\n",
        "print(\"Accuracy:\", faster_rcnn_accuracy)\n",
        "print(\"F1 Score:\", faster_rcnn_f1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z8jtmmfs7wSE"
      },
      "outputs": [],
      "source": [
        "import torchvision.models as models\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "import time\n",
        "\n",
        "# Define function to fine-tune pre-trained model\n",
        "def fine_tune(model, train_loader, test_loader, optimizer, criterion, num_epochs=2):\n",
        "    start_time = time.time()\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        for images, labels in train_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        # Print average loss after each epoch\n",
        "        print(f\"Epoch {epoch+1}, Loss: {running_loss/len(train_loader)}\")\n",
        "\n",
        "    end_time = time.time()\n",
        "    print(f\"Training time: {end_time - start_time} seconds\")\n",
        "\n",
        "    # Evaluate model on test set\n",
        "    model.eval()\n",
        "    test_predictions = []\n",
        "    true_labels = []\n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            test_predictions.extend(predicted.cpu().numpy())\n",
        "            true_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    # Calculate accuracy and F1 score\n",
        "    accuracy = accuracy_score(true_labels, test_predictions)\n",
        "    f1 = f1_score(true_labels, test_predictions, average='weighted')\n",
        "\n",
        "    return accuracy, f1\n",
        "\n",
        "# Load pre-trained VGG16 model\n",
        "vgg16_model = models.vgg16(pretrained=True)\n",
        "\n",
        "# Modify the first convolutional layer to accept single-channel images\n",
        "vgg16_model.features[0] = nn.Conv2d(1, 64, kernel_size=3, padding=1)\n",
        "\n",
        "# Modify the classifier part of VGG16 to fit the MNIST dataset (10 output classes)\n",
        "num_features = vgg16_model.classifier[0].in_features\n",
        "vgg16_model.classifier = nn.Sequential(\n",
        "    nn.Linear(num_features, 256),\n",
        "    nn.ReLU(True),\n",
        "    nn.Dropout(),\n",
        "    nn.Linear(256, 128),\n",
        "    nn.ReLU(True),\n",
        "    nn.Dropout(),\n",
        "    nn.Linear(128, 10)\n",
        ")\n",
        "\n",
        "# Move model to GPU if available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "vgg16_model.to(device)\n",
        "\n",
        "# Define optimizer and criterion\n",
        "vgg16_optimizer = optim.SGD(vgg16_model.parameters(), lr=0.001, momentum=0.9)\n",
        "vgg16_criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Fine-tune VGG16 model\n",
        "vgg16_accuracy, vgg16_f1 = fine_tune(vgg16_model, trainloader, testloader, vgg16_optimizer, vgg16_criterion)\n",
        "\n",
        "# Print results\n",
        "print(\"VGG16 Model:\")\n",
        "print(\"Accuracy:\", vgg16_accuracy)\n",
        "print(\"F1 Score:\", vgg16_f1)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
